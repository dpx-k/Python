{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76e20b",
   "metadata": {},
   "source": [
    "## Basic Methods and Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63fa72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dataframe is a basic data structure in python which stores data in tabular format\n",
    "df = pd.DataFrame([[1,2,3],[4,5,6],[7,8,9]], columns= [\"A\", \"B\", \"C\"], index = ['x', 'y', 'z'])\n",
    "\n",
    "# print the whole data frame\n",
    "print(df, '\\n')\n",
    "\n",
    "#print the first two rows \n",
    "print(df.head(2), '\\n') \n",
    "\n",
    "#print last two rows\n",
    "print(df.tail(2), '\\n')\n",
    "\n",
    "# by default the head and tail without parameters gives the first and last rows respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f92ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the columns\n",
    "print(df.columns)\n",
    "\n",
    "# print the indices\n",
    "print(list(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f30420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the info about the dataframe \n",
    "print(df.info())\n",
    "\n",
    "# print some other meaningful info\n",
    "print(df.describe())\n",
    "\n",
    "# print unique values\n",
    "print(df.nunique())\n",
    "\n",
    "# print the dimensions of the dataframe \n",
    "print(df.shape)\n",
    "\n",
    "# print the number of elements in the dataframe\n",
    "print(df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a9ce79",
   "metadata": {},
   "source": [
    "## Loading in DataFrames from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df112ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "education = pd.read_csv(\"datasets/International_Education_Costs.csv\")\n",
    "\n",
    "# apply the above operations\n",
    "print(\"Head: \\n\", education.head(),'\\n')\n",
    "print(\"Tail: \\n\", education.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(education.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757895d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(education.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f50313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(education.shape)\n",
    "print(education.size)\n",
    "\n",
    "print(list(education.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcbc4b7",
   "metadata": {},
   "source": [
    "## Loading different types of files\n",
    "\n",
    "---\n",
    "\n",
    "### **CSV (Comma-Separated Values)**\n",
    "\n",
    "* Stores tabular data in plain text format.\n",
    "* Each line represents a row; columns are separated by commas.\n",
    "* **Human-readable** and can be opened with text editors or Excel.\n",
    "* Does **not** store data types or schemaâ€”everything is treated as text.\n",
    "* **No compression** or indexing; results in **larger file sizes**.\n",
    "* **Slower** to read/write, especially with large datasets.\n",
    "* Still widely used due to its **simplicity and compatibility** across tools.\n",
    "\n",
    "---\n",
    "\n",
    "### **Feather**\n",
    "\n",
    "* A **binary columnar format** optimized for fast data reading/writing.\n",
    "* Part of the **Apache Arrow** ecosystem.\n",
    "* Designed for **in-memory analytics**, especially with **Pandas** and **R**.\n",
    "* **Preserves data types and schema**, unlike CSV.\n",
    "* Supports **lightweight compression**.\n",
    "* **Not human-readable**, but much faster and more space-efficient than CSV.\n",
    "* Ideal for **medium-sized datasets** and fast data exchange between tools.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parquet**\n",
    "\n",
    "* A **highly efficient columnar storage format** developed by Apache.\n",
    "* Best suited for **big data systems** like Spark, Hadoop, and cloud storage.\n",
    "* Supports **compression**, **indexing**, and **complex nested data**.\n",
    "* Retains detailed **schema and data types**.\n",
    "* **Not human-readable**, but excellent for performance and scalability.\n",
    "* Enables **fast access to specific columns**, improving query speed.\n",
    "* Ideal for **large datasets**, data lakes, and distributed data processing.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e96f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios = pd.read_csv(\"datasets/bios.csv\") # csv file\n",
    "bios.info()\n",
    "bios.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99091da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_parquet(\"datasets/results.parquet\") # parquet file\n",
    "results.info()\n",
    "results.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c156c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_results = pd.read_feather(\"datasets/results.feather\") # feather file\n",
    "f_results.info()\n",
    "f_results.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics = pd.read_excel(\"datasets/olympics-data.xlsx\") # excel file\n",
    "olympics.info()\n",
    "olympics.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af589da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can convert files from one to another \n",
    "\n",
    "parkayy = bios.to_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7bec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the display function to view the entire datset (displays the first 5 and last 5 rows)\n",
    "display(bios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c3b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access random rows using the sample function \n",
    "bios.sample(10, random_state=1) # setting random_state to True doesn't change the rows each time you run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing using loc and iloc \n",
    "\n",
    "# dataset.loc[] - Used to access rows and columns by their labels (names). (label based indexing)\n",
    "# dataset.iloc[] - Used to access rows and columns by their integer positions (like a 2D array). (integer location based indexing)\n",
    "# dataset.loc[[rows],[columns]]\n",
    "bios.loc[0] # returns the first row\n",
    "\n",
    "bios.loc[[0,1,2]] # returns the first 3 rows\n",
    "bios.loc[[23,47,89]] # returns the 23rd, 47th and 89th rows \n",
    "\n",
    "# you can do indexing too \n",
    "bios.loc[5:10]\n",
    "\n",
    "# specify column name with row slice\n",
    "bios.loc[5:8, [\"name\", \"born_date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40ae275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bios.loc[35450:35455, \"height\"] = 172.5\n",
    "bios.loc[35450:35455, ['name', 'height']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0931a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessing objects at specific index using at and iat \n",
    "\n",
    "print(bios.at[45678, 'name'])\n",
    "print(bios.iat[45678, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6470fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = pd.read_csv('datasets/coffee.csv')\n",
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18314052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting\n",
    "\n",
    "coffee.sort_values([\"Units Sold\"])\n",
    "\n",
    "\n",
    "# sort in descending order, add more parameters for the sort\n",
    "coffee.sort_values([\"Units Sold\", 'Coffee Type'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f3d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through rows using a for loops \n",
    "\n",
    "for index, row in coffee.iterrows(): \n",
    "    print(index)\n",
    "    print(row['Units Sold'],'\\n') # you can grab a specific row\n",
    "\n",
    "for index, row in coffee.iterrows(): \n",
    "    print(index, row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cortex_engine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
